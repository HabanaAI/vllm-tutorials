{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[4.59375]]], "params": {"weight": [[0.67578125]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[0.77734375]]], "outputs": [[[0.51171875]], [[1.782693347283291e+23]]], "params": {"weight": [[0.314453125]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.828125]], [[13.8125]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[2.828125]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.0]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[13.8125]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[1.3359375]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[22.625]], [[13.8125]], [[1.3359375]]], "outputs": [[[0.77734375]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[2.765625]]], "params": {"weight": [[0.59375]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[32.75]]], "outputs": [[[20.875]], [[3.853088372275746e+28]]], "params": {"weight": [[0.62109375]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[5.84375]]], "params": {"weight": [[0.40234375]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[1.8984375]]], "outputs": [[[0.6171875]], [[7.272897730801609e+28]]], "params": {"weight": [[0.51953125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.640625]], [[14.0625]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.375]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.640625]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.6796875]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[14.0625]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[2.375]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.5625]], [[14.0625]], [[2.375]]], "outputs": [[[1.8984375]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[18.5]]], "params": {"weight": [[1.1328125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[1160.0]]], "outputs": [[[408.0]], [[6.313494200355439e+28]]], "params": {"weight": [[0.6796875]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[8.0]]], "params": {"weight": [[0.54296875]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[1.3046875]]], "outputs": [[[0.84765625]], [[1.1760430373211113e+29]]], "params": {"weight": [[0.359375]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.4765625]], [[15.5]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.640625]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.4765625]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.609375]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[15.5]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[2.640625]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.5625]], [[15.5]], [[2.640625]]], "outputs": [[[1.3046875]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[6.625]]], "params": {"weight": [[0.4609375]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[3.203125]]], "outputs": [[[1.3359375]], [[4.4875326424095035e+28]]], "params": {"weight": [[0.53125]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[7.0]]], "params": {"weight": [[0.3046875]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[1.859375]]], "outputs": [[[0.9375]], [[6.034957691516229e+28]]], "params": {"weight": [[0.2431640625]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.546875]], [[20.625]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.59375]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.546875]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.984375]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[20.625]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[2.59375]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.0625]], [[20.625]], [[2.59375]]], "outputs": [[[1.859375]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[6.875]]], "params": {"weight": [[0.337890625]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[4.15625]]], "outputs": [[[1.1015625]], [[7.272897730801609e+28]]], "params": {"weight": [[0.490234375]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[6.34375]]], "params": {"weight": [[0.416015625]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[1.484375]]], "outputs": [[[0.91015625]], [[8.046610255354972e+28]]], "params": {"weight": [[0.3984375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.546875]], [[18.5]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.015625]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.546875]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.6171875]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[18.5]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[2.015625]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.4375]], [[18.5]], [[2.015625]]], "outputs": [[[1.484375]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[6.9375]]], "params": {"weight": [[0.515625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[3.796875]]], "outputs": [[[1.28125]], [[6.034957691516229e+28]]], "params": {"weight": [[0.470703125]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[10.4375]]], "params": {"weight": [[1.109375]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[1.9140625]]], "outputs": [[[1.1328125]], [[6.034957691516229e+28]]], "params": {"weight": [[0.447265625]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.4609375]], [[20.0]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.828125]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.4609375]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.15625]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[20.0]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[2.828125]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.3125]], [[20.0]], [[2.828125]]], "outputs": [[[1.9140625]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[7.03125]]], "params": {"weight": [[0.357421875]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[4.4375]]], "outputs": [[[1.6953125]], [[3.853088372275746e+28]]], "params": {"weight": [[0.45703125]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[8.75]]], "params": {"weight": [[0.3828125]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[1.7890625]]], "outputs": [[[1.2109375]], [[1.064628433785427e+29]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.5078125]], [[21.125]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.421875]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.5078125]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.7734375]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[21.125]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[2.421875]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[13.8125]], [[21.125]], [[2.421875]]], "outputs": [[[1.7890625]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[6.75]]], "params": {"weight": [[0.451171875]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[4.15625]]], "outputs": [[[1.765625]], [[6.034957691516229e+28]]], "params": {"weight": [[0.625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[9.1875]]], "params": {"weight": [[0.33203125]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[1.90625]]], "outputs": [[[1.359375]], [[5.385039170891404e+28]]], "params": {"weight": [[0.3671875]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.5703125]], [[18.5]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.4375]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.5703125]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[3.4375]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[18.5]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[3.4375]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.5625]], [[18.5]], [[3.4375]]], "outputs": [[[1.75]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[6.90625]]], "params": {"weight": [[0.5859375]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[3.109375]]], "outputs": [[[2.546875]], [[5.385039170891404e+28]]], "params": {"weight": [[0.48046875]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[10.625]]], "params": {"weight": [[0.498046875]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[1.875]]], "outputs": [[[2.03125]], [[3.3269638555794595e+28]]], "params": {"weight": [[0.404296875]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.3046875]], [[19.0]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.421875]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.3046875]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.046875]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[19.0]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[2.421875]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.75]], [[19.0]], [[2.421875]]], "outputs": [[[1.875]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[7.3125]]], "params": {"weight": [[0.546875]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[5.46875]]], "outputs": [[[2.484375]], [[5.385039170891404e+28]]], "params": {"weight": [[0.578125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[9.875]]], "params": {"weight": [[0.412109375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[1.84375]]], "outputs": [[[2.1875]], [[5.385039170891404e+28]]], "params": {"weight": [[0.498046875]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.6640625]], [[19.375]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.796875]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.6640625]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[1.984375]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[19.375]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[2.796875]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.5625]], [[19.375]], [[2.796875]]], "outputs": [[[1.84375]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[7.5]]], "params": {"weight": [[0.51171875]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[6.34375]]], "outputs": [[[2.421875]], [[2.0306175876339474e+23]]], "params": {"weight": [[0.5546875]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[15.25]]], "params": {"weight": [[0.38671875]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[2.125]]], "outputs": [[[1.5546875]], [[7.55143423964082e+28]]], "params": {"weight": [[0.60546875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.9140625]], [[17.25]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.078125]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.9140625]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.171875]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[17.25]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[3.078125]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[16.375]], [[17.25]], [[3.078125]]], "outputs": [[[2.125]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[7.875]]], "params": {"weight": [[0.57421875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[10.75]]], "outputs": [[[1.7578125]], [[1.064628433785427e+29]]], "params": {"weight": [[0.515625]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[13.5]]], "params": {"weight": [[0.431640625]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[1.8828125]]], "outputs": [[[1.7734375]], [[5.385039170891404e+28]]], "params": {"weight": [[0.6328125]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.4375]], [[22.0]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[2.78125]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.4375]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.109375]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[22.0]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[2.78125]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[12.25]], [[22.0]], [[2.78125]]], "outputs": [[[1.8828125]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[7.8125]]], "params": {"weight": [[0.63671875]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[8.8125]]], "outputs": [[[2.921875]], [[1.3222626152035007e+23]]], "params": {"weight": [[0.38671875]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[12.75]]], "params": {"weight": [[0.73828125]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[1.8125]]], "outputs": [[[2.6875]], [[1.1760430373211113e+29]]], "params": {"weight": [[0.6953125]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.921875]], [[17.625]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.8125]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.921875]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.46875]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[17.625]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[3.8125]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.125]], [[16.75]], [[3.140625]]], "outputs": [[[1.8125]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[7.71875]]], "params": {"weight": [[0.59765625]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[10.625]]], "outputs": [[[2.96875]], [[8.294198263212048e+28]]], "params": {"weight": [[0.62890625]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[13.9375]]], "params": {"weight": [[0.51953125]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[2.65625]]], "outputs": [[[3.203125]], [[4.4875326424095035e+28]]], "params": {"weight": [[0.462890625]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.015625]], [[19.625]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[3.75]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[2.015625]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[2.96875]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[19.625]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[3.75]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[15.4375]], [[19.625]], [[3.75]]], "outputs": [[[2.65625]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[7.15625]]], "params": {"weight": [[0.6640625]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[13.3125]]], "outputs": [[[3.765625]], [[3.1567471001777197e+28]]], "params": {"weight": [[0.451171875]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[12.8125]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[2.546875]]], "outputs": [[[5.1875]], [[4.7351206502665796e+28]]], "params": {"weight": [[0.359375]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.125]], [[16.0]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[6.4375]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[2.125]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[5.125]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[16.0]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[6.4375]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.25]], [[15.75]], [[6.4375]]], "outputs": [[[2.546875]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[9.9375]]], "params": {"weight": [[0.7578125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[16.875]]], "outputs": [[[6.125]], [[8.232301261247779e+28]]], "params": {"weight": [[0.4453125]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[8.75]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[4.25]]], "outputs": [[[5.75]], [[1.4285158610680677e+23]]], "params": {"weight": [[0.71875]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.28125]], [[22.25]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[5.09375]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[2.28125]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[4.78125]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[22.25]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[5.09375]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[17.625]], [[21.875]], [[5.09375]]], "outputs": [[[4.25]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[10.0]]], "params": {"weight": [[1.1953125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[258.0]]], "outputs": [[[256.0]], [[3.1567471001777197e+28]]], "params": {"weight": [[0.828125]]}}, "lm_head": {"inputs": [[[36.25]]], "params": {"weight": [[0.361328125]]}}}}