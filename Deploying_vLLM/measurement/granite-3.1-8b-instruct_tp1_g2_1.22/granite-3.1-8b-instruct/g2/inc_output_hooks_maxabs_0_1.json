{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[692.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[35.0]]], "outputs": [[[34.75]], [[1.1735671572425405e+30]]], "params": {"weight": [[0.546875]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.21875]], [[200.0]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[62.25]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[175.0]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[49.25]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[200.0]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[62.25]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[156.0]], [[200.0]], [[62.25]]], "outputs": [[[35.0]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[144.0]]], "params": {"weight": [[0.82421875]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[192.0]]], "outputs": [[[113.5]], [[1.1735671572425405e+30]]], "params": {"weight": [[0.9453125]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[164.0]]], "params": {"weight": [[0.466796875]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[10.25]]], "outputs": [[[9.5625]], [[7.853348998533927e+34]]], "params": {"weight": [[0.42578125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.30859375]], [[118.0]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.625]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[97.5]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[45.0]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[118.0]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[13.625]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[41.25]], [[118.0]], [[13.625]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[94.5]]], "params": {"weight": [[0.423828125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[132.0]]], "outputs": [[[50.5]], [[6.065906192498363e+29]]], "params": {"weight": [[0.392578125]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[117.0]]], "params": {"weight": [[0.408203125]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[9.625]]], "outputs": [[[13.1875]], [[9.605749188289431e+34]]], "params": {"weight": [[0.478515625]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.2265625]], [[83.0]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[109.5]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[53.25]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[83.0]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[10.9375]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[30.625]], [[83.0]], [[10.9375]]], "outputs": [[[9.625]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[54.25]]], "params": {"weight": [[0.55078125]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[2688.0]]], "outputs": [[[1992.0]], [[1.7529230956280985e+30]]], "params": {"weight": [[0.66796875]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[109.0]]], "params": {"weight": [[0.4375]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[6.96875]], [[2.596148429267414e+33]]], "params": {"weight": [[0.32421875]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.375]], [[78.5]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[11.1875]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[100.0]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[54.5]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[78.5]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[11.1875]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.0]], [[78.5]], [[11.1875]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[21.625]]], "params": {"weight": [[0.251953125]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[76.5]]], "outputs": [[[89.0]], [[2.596148429267414e+33]]], "params": {"weight": [[0.5390625]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[145.0]]], "params": {"weight": [[0.2021484375]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[9.75]]], "outputs": [[[6.875]], [[6.3930155070710065e+34]]], "params": {"weight": [[0.359375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.400390625]], [[76.5]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.25]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[209.0]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[105.5]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[14.25]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.0]], [[76.5]], [[14.25]]], "outputs": [[[9.75]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[28.75]]], "params": {"weight": [[0.384765625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[2144.0]]], "outputs": [[[2496.0]], [[6.3930155070710065e+34]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[177.0]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[10.3125]]], "outputs": [[[11.625]], [[9.086519502435948e+34]]], "params": {"weight": [[0.453125]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.419921875]], [[72.0]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[200.0]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[101.5]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[72.0]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.25]], [[72.0]], [[15.4375]]], "outputs": [[[10.3125]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[103.5]]], "params": {"weight": [[0.400390625]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[28032.0]]], "outputs": [[[22272.0]], [[9.086519502435948e+34]]], "params": {"weight": [[0.76171875]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[17.125]], [[1.9188070608923394e+28]]], "params": {"weight": [[0.353515625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.43359375]], [[73.0]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[24.0]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[25.125]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[13.5625]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[73.0]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[24.0]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[58.25]], [[72.5]], [[24.0]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[52.75]]], "params": {"weight": [[0.314453125]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[49.25]]], "outputs": [[[24.75]], [[1.9188070608923394e+28]]], "params": {"weight": [[0.44140625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[152.0]]], "params": {"weight": [[0.22265625]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[9.25]]], "outputs": [[[12.5625]], [[9.086519502435948e+34]]], "params": {"weight": [[0.48828125]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.435546875]], [[66.0]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[11.9375]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[20.125]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[14.8125]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[66.0]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[11.9375]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.25]], [[66.0]], [[11.9375]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[33.5]]], "params": {"weight": [[0.3125]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[60.25]]], "outputs": [[[20.75]], [[9.086519502435948e+34]]], "params": {"weight": [[0.5]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[208.0]]], "params": {"weight": [[0.2041015625]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[8.5625]]], "outputs": [[[12.8125]], [[7.626186010973028e+34]]], "params": {"weight": [[0.43359375]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.431640625]], [[73.5]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.4375]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[23.25]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[17.375]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[14.4375]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[65.5]], [[72.5]], [[14.4375]]], "outputs": [[[8.5625]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[29.0]]], "params": {"weight": [[0.28515625]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[42.5]]], "outputs": [[[14.5]], [[7.626186010973028e+34]]], "params": {"weight": [[0.58203125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[206.0]]], "params": {"weight": [[0.302734375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[9.25]]], "outputs": [[[12.5]], [[1.0514401138533026e+35]]], "params": {"weight": [[0.333984375]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.46875]], [[74.0]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.25]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[16.75]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[14.125]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[74.0]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[12.25]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[74.0]], [[12.25]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[26.0]]], "params": {"weight": [[0.3359375]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[34.25]]], "outputs": [[[18.0]], [[1.0514401138533026e+35]]], "params": {"weight": [[0.5390625]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[219.0]]], "params": {"weight": [[0.267578125]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[11.5]]], "outputs": [[[14.6875]], [[8.1778675521923535e+34]]], "params": {"weight": [[0.54296875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.462890625]], [[76.5]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.75]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[19.875]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[13.0]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[12.75]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[69.5]], [[76.5]], [[12.75]]], "outputs": [[[11.5]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[25.875]]], "params": {"weight": [[0.341796875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[34.0]]], "outputs": [[[18.0]], [[8.1778675521923535e+34]]], "params": {"weight": [[0.57421875]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[250.0]]], "params": {"weight": [[0.28125]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[11.3125]]], "outputs": [[[15.5]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.359375]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.435546875]], [[79.0]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[23.5]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[14.4375]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[79.0]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[70.5]], [[79.0]], [[15.4375]]], "outputs": [[[11.3125]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[26.5]]], "params": {"weight": [[0.349609375]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[41.75]]], "outputs": [[[18.125]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.443359375]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[322.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[10.9375]]], "outputs": [[[12.75]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.431640625]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.453125]], [[75.0]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.4375]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[29.5]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[17.125]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[75.0]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[13.4375]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[75.0]], [[13.4375]]], "outputs": [[[10.9375]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.345703125]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[38.0]]], "outputs": [[[22.25]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.482421875]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[248.0]]], "params": {"weight": [[0.353515625]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[10.1875]]], "outputs": [[[16.75]], [[9.086519502435948e+34]]], "params": {"weight": [[0.71875]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.478515625]], [[78.5]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.125]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[25.875]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[15.875]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[78.5]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[14.125]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.0]], [[78.5]], [[14.125]]], "outputs": [[[10.1875]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[27.125]]], "params": {"weight": [[0.27734375]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[29.0]]], "outputs": [[[25.125]], [[9.086519502435948e+34]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[245.0]]], "params": {"weight": [[0.1708984375]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[12.3125]]], "outputs": [[[25.25]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.70703125]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.392578125]], [[78.0]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[30.25]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[33.0]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.5]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[30.25]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[55.25]], [[78.0]], [[30.25]]], "outputs": [[[12.3125]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[29.25]]], "params": {"weight": [[0.28125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[46.5]]], "outputs": [[[40.25]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.6015625]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[214.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[11.1875]]], "outputs": [[[33.75]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.3828125]], [[94.5]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.9375]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[37.0]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.125]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[94.5]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[15.9375]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.25]], [[87.0]], [[15.0625]]], "outputs": [[[11.1875]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[27.375]]], "params": {"weight": [[0.328125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[35.75]]], "outputs": [[[51.5]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.640625]]}}, "model.layers.16.self_attn.qkv_proj": {"inputs": [[[189.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.16.self_attn.o_proj": {"inputs": [[[12.1875]]], "outputs": [[[35.5]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.41015625]]}}, "model.layers.16.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4140625]], [[87.5]]]}, "model.layers.16.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.25]]]}, "model.layers.16.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[31.125]]]}, "model.layers.16.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.5]]]}, "model.layers.16.self_attn.attn.impl.k_cache": {"inputs": [[[87.5]]]}, "model.layers.16.self_attn.attn.impl.v_cache": {"inputs": [[[16.25]]]}, "model.layers.16.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[57.5]], [[87.5]], [[16.25]]], "outputs": [[[12.1875]], [[1.0]]]}, "model.layers.16.mlp.gate_up_proj": {"inputs": [[[30.375]]], "params": {"weight": [[0.30859375]]}}, "model.layers.16.mlp.down_proj": {"inputs": [[[44.0]]], "outputs": [[[36.75]], [[1.1358149378044935e+35]]], "params": {"weight": [[0.6875]]}}, "model.layers.17.self_attn.qkv_proj": {"inputs": [[[193.0]]], "params": {"weight": [[0.1767578125]]}}, "model.layers.17.self_attn.o_proj": {"inputs": [[[12.4375]]], "outputs": [[[32.25]], [[9.086519502435948e+34]]], "params": {"weight": [[0.37890625]]}}, "model.layers.17.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4375]], [[80.0]]]}, "model.layers.17.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.625]]]}, "model.layers.17.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[29.375]]]}, "model.layers.17.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.75]]]}, "model.layers.17.self_attn.attn.impl.k_cache": {"inputs": [[[80.0]]]}, "model.layers.17.self_attn.attn.impl.v_cache": {"inputs": [[[13.625]]]}, "model.layers.17.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[61.0]], [[80.0]], [[13.625]]], "outputs": [[[12.4375]], [[1.0]]]}, "model.layers.17.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.298828125]]}}, "model.layers.17.mlp.down_proj": {"inputs": [[[59.25]]], "outputs": [[[26.75]], [[9.086519502435948e+34]]], "params": {"weight": [[0.62890625]]}}, "model.layers.18.self_attn.qkv_proj": {"inputs": [[[153.0]]], "params": {"weight": [[0.189453125]]}}, "model.layers.18.self_attn.o_proj": {"inputs": [[[14.875]]], "outputs": [[[15.4375]], [[7.626186010973028e+34]]], "params": {"weight": [[0.2578125]]}}, "model.layers.18.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.48046875]], [[75.5]]]}, "model.layers.18.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[18.375]]]}, "model.layers.18.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[26.25]]]}, "model.layers.18.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.75]]]}, "model.layers.18.self_attn.attn.impl.k_cache": {"inputs": [[[75.5]]]}, "model.layers.18.self_attn.attn.impl.v_cache": {"inputs": [[[18.375]]]}, "model.layers.18.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[64.0]], [[75.5]], [[18.375]]], "outputs": [[[14.875]], [[1.0]]]}, "model.layers.18.mlp.gate_up_proj": {"inputs": [[[31.625]]], "params": {"weight": [[0.330078125]]}}, "model.layers.18.mlp.down_proj": {"inputs": [[[61.75]]], "outputs": [[[45.25]], [[7.626186010973028e+34]]], "params": {"weight": [[0.625]]}}, "model.layers.19.self_attn.qkv_proj": {"inputs": [[[154.0]]], "params": {"weight": [[0.1884765625]]}}, "model.layers.19.self_attn.o_proj": {"inputs": [[[14.25]]], "outputs": [[[39.0]], [[1.9212829409709102e+30]]], "params": {"weight": [[0.40625]]}}, "model.layers.19.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.474609375]], [[86.5]]]}, "model.layers.19.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[23.625]]]}, "model.layers.19.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[34.0]]]}, "model.layers.19.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.25]]]}, "model.layers.19.self_attn.attn.impl.k_cache": {"inputs": [[[86.5]]]}, "model.layers.19.self_attn.attn.impl.v_cache": {"inputs": [[[23.625]]]}, "model.layers.19.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[62.5]], [[86.5]], [[23.625]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.19.mlp.gate_up_proj": {"inputs": [[[37.0]]], "params": {"weight": [[0.52734375]]}}, "model.layers.19.mlp.down_proj": {"inputs": [[[376.0]]], "outputs": [[[107.5]], [[1.9212829409709102e+30]]], "params": {"weight": [[0.67578125]]}}, "model.layers.20.self_attn.qkv_proj": {"inputs": [[[0.77734375]]], "params": {"weight": [[0.07275390625]]}}, "model.layers.20.self_attn.o_proj": {"inputs": [[[0.138671875]]], "outputs": [[[0.416015625]], [[1.1438565962996914e+30]]], "params": {"weight": [[0.27734375]]}}, "model.layers.20.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.042977312465837e-16]], [[1.199040866595169e-13]]]}, "model.layers.20.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.287109375]]]}, "model.layers.20.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.20.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.20.self_attn.attn.impl.k_cache": {"inputs": [[[1.199040866595169e-13]]]}, "model.layers.20.self_attn.attn.impl.v_cache": {"inputs": [[[0.287109375]]]}, "model.layers.20.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.0391687510491465e-13]], [[1.199040866595169e-13]], [[0.287109375]]], "outputs": [[[0.138671875]], [[1.0]]]}, "model.layers.20.mlp.gate_up_proj": {"inputs": [[[35.25]]], "params": {"weight": [[0.388671875]]}}, "model.layers.20.mlp.down_proj": {"inputs": [[[77.0]]], "outputs": [[[31.375]], [[1.1438565962996914e+30]]], "params": {"weight": [[0.69140625]]}}, "model.layers.21.self_attn.qkv_proj": {"inputs": [[[157.0]]], "params": {"weight": [[0.166015625]]}}, "model.layers.21.self_attn.o_proj": {"inputs": [[[14.5]]], "outputs": [[[36.75]], [[7.081017024712375e+29]]], "params": {"weight": [[0.4609375]]}}, "model.layers.21.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.52734375]], [[75.0]]]}, "model.layers.21.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.21.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[29.125]]]}, "model.layers.21.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[14.8125]]]}, "model.layers.21.self_attn.attn.impl.k_cache": {"inputs": [[[75.0]]]}, "model.layers.21.self_attn.attn.impl.v_cache": {"inputs": [[[20.5]]]}, "model.layers.21.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.0]], [[74.5]], [[20.5]]], "outputs": [[[14.5]], [[1.0]]]}, "model.layers.21.mlp.gate_up_proj": {"inputs": [[[39.75]]], "params": {"weight": [[0.37890625]]}}, "model.layers.21.mlp.down_proj": {"inputs": [[[74.0]]], "outputs": [[[21.25]], [[7.081017024712375e+29]]], "params": {"weight": [[0.56640625]]}}, "model.layers.22.self_attn.qkv_proj": {"inputs": [[[163.0]]], "params": {"weight": [[0.154296875]]}}, "model.layers.22.self_attn.o_proj": {"inputs": [[[10.625]]], "outputs": [[[12.8125]], [[2.4882594789636144e+29]]], "params": {"weight": [[0.28515625]]}}, "model.layers.22.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.54296875]], [[71.5]]]}, "model.layers.22.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.0]]]}, "model.layers.22.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[18.0]]]}, "model.layers.22.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[13.6875]]]}, "model.layers.22.self_attn.attn.impl.k_cache": {"inputs": [[[71.5]]]}, "model.layers.22.self_attn.attn.impl.v_cache": {"inputs": [[[17.0]]]}, "model.layers.22.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[71.5]], [[71.5]], [[17.0]]], "outputs": [[[10.1875]], [[1.0]]]}, "model.layers.22.mlp.gate_up_proj": {"inputs": [[[41.75]]], "params": {"weight": [[0.208984375]]}}, "model.layers.22.mlp.down_proj": {"inputs": [[[107.5]]], "outputs": [[[33.25]], [[2.4882594789636144e+29]]], "params": {"weight": [[0.578125]]}}, "model.layers.23.self_attn.qkv_proj": {"inputs": [[[1.1328125]]], "params": {"weight": [[0.04541015625]]}}, "model.layers.23.self_attn.o_proj": {"inputs": [[[0.06591796875]]], "outputs": [[[0.12890625]], [[1.9212829409709102e+30]]], "params": {"weight": [[0.11865234375]]}}, "model.layers.23.self_attn.attn.impl.matmul_qk": {"inputs": [[[4.961309141293668e-16]], [[1.0169642905566434e-13]]]}, "model.layers.23.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.173828125]]]}, "model.layers.23.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.23.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.23.self_attn.attn.impl.k_cache": {"inputs": [[[1.0169642905566434e-13]]]}, "model.layers.23.self_attn.attn.impl.v_cache": {"inputs": [[[0.173828125]]]}, "model.layers.23.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.72715225139109e-14]], [[1.0169642905566434e-13]], [[0.173828125]]], "outputs": [[[0.06591796875]], [[1.0]]]}, "model.layers.23.mlp.gate_up_proj": {"inputs": [[[43.75]]], "params": {"weight": [[0.3515625]]}}, "model.layers.23.mlp.down_proj": {"inputs": [[[168.0]]], "outputs": [[[13.0625]], [[1.9212829409709102e+30]]], "params": {"weight": [[0.484375]]}}, "model.layers.24.self_attn.qkv_proj": {"inputs": [[[1.0625]]], "params": {"weight": [[0.044189453125]]}}, "model.layers.24.self_attn.o_proj": {"inputs": [[[0.0615234375]]], "outputs": [[[0.279296875]], [[2.141636267963708e+29]]], "params": {"weight": [[0.1181640625]]}}, "model.layers.24.self_attn.attn.impl.matmul_qk": {"inputs": [[[5.169475958410885e-16]], [[8.526512829121202e-14]]]}, "model.layers.24.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.24.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.24.self_attn.attn.impl.k_cache": {"inputs": [[[8.526512829121202e-14]]]}, "model.layers.24.self_attn.attn.impl.v_cache": {"inputs": [[[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.682743330406083e-14]], [[8.038014698286133e-14]], [[0.197265625]]], "outputs": [[[0.0615234375]], [[1.0]]]}, "model.layers.24.mlp.gate_up_proj": {"inputs": [[[43.25]]], "params": {"weight": [[0.2333984375]]}}, "model.layers.24.mlp.down_proj": {"inputs": [[[85.0]]], "outputs": [[[14.75]], [[2.141636267963708e+29]]], "params": {"weight": [[0.48828125]]}}, "model.layers.25.self_attn.qkv_proj": {"inputs": [[[176.0]]], "params": {"weight": [[0.220703125]]}}, "model.layers.25.self_attn.o_proj": {"inputs": [[[10.875]]], "outputs": [[[8.3125]], [[5.387007990729884e+34]]], "params": {"weight": [[0.38671875]]}}, "model.layers.25.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.58203125]], [[72.0]]]}, "model.layers.25.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.3125]]]}, "model.layers.25.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[19.25]]]}, "model.layers.25.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.5]]]}, "model.layers.25.self_attn.attn.impl.k_cache": {"inputs": [[[72.0]]]}, "model.layers.25.self_attn.attn.impl.v_cache": {"inputs": [[[15.3125]]]}, "model.layers.25.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[80.0]], [[72.0]], [[15.3125]]], "outputs": [[[10.875]], [[1.0]]]}, "model.layers.25.mlp.gate_up_proj": {"inputs": [[[47.75]]], "params": {"weight": [[0.28515625]]}}, "model.layers.25.mlp.down_proj": {"inputs": [[[113.5]]], "outputs": [[[29.625]], [[5.387007990729884e+34]]], "params": {"weight": [[0.61328125]]}}, "model.layers.26.self_attn.qkv_proj": {"inputs": [[[1.6640625]]], "params": {"weight": [[0.058349609375]]}}, "model.layers.26.self_attn.o_proj": {"inputs": [[[0.08544921875]]], "outputs": [[[0.201171875]], [[5.387007990729884e+34]]], "params": {"weight": [[0.166015625]]}}, "model.layers.26.self_attn.attn.impl.matmul_qk": {"inputs": [[[6.314393452555578e-16]], [[1.0791367799356522e-13]]]}, "model.layers.26.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.26.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.26.self_attn.attn.impl.k_cache": {"inputs": [[[1.0791367799356522e-13]]]}, "model.layers.26.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[9.414691248821327e-14]], [[1.0791367799356522e-13]], [[0.28515625]]], "outputs": [[[0.08544921875]], [[1.0]]]}, "model.layers.26.mlp.gate_up_proj": {"inputs": [[[55.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.26.mlp.down_proj": {"inputs": [[[336.0]]], "outputs": [[[102.0]], [[5.387007990729884e+34]]], "params": {"weight": [[0.419921875]]}}, "model.layers.27.self_attn.qkv_proj": {"inputs": [[[1.7421875]]], "params": {"weight": [[0.06689453125]]}}, "model.layers.27.self_attn.o_proj": {"inputs": [[[0.1259765625]]], "outputs": [[[0.384765625]], [[5.387007990729884e+34]]], "params": {"weight": [[0.1640625]]}}, "model.layers.27.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.28583859910259e-16]], [[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.27.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.27.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.27.self_attn.attn.impl.k_cache": {"inputs": [[[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.27.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.199040866595169e-13]], [[1.412203687323199e-13]], [[0.28515625]]], "outputs": [[[0.1259765625]], [[1.0]]]}, "model.layers.27.mlp.gate_up_proj": {"inputs": [[[62.5]]], "params": {"weight": [[0.6640625]]}}, "model.layers.27.mlp.down_proj": {"inputs": [[[155.0]]], "outputs": [[[17.75]], [[5.387007990729884e+34]]], "params": {"weight": [[0.5546875]]}}, "model.layers.28.self_attn.qkv_proj": {"inputs": [[[169.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.28.self_attn.o_proj": {"inputs": [[[14.9375]]], "outputs": [[[9.4375]], [[5.387007990729884e+34]]], "params": {"weight": [[0.87109375]]}}, "model.layers.28.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.52734375]], [[73.5]]]}, "model.layers.28.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[25.25]]]}, "model.layers.28.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[11.5625]]]}, "model.layers.28.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[19.625]]]}, "model.layers.28.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.28.self_attn.attn.impl.v_cache": {"inputs": [[[25.25]]]}, "model.layers.28.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[67.5]], [[72.0]], [[25.25]]], "outputs": [[[14.9375]], [[1.0]]]}, "model.layers.28.mlp.gate_up_proj": {"inputs": [[[56.5]]], "params": {"weight": [[0.2451171875]]}}, "model.layers.28.mlp.down_proj": {"inputs": [[[139.0]]], "outputs": [[[28.875]], [[5.387007990729884e+34]]], "params": {"weight": [[0.5859375]]}}, "model.layers.29.self_attn.qkv_proj": {"inputs": [[[5.53125]]], "params": {"weight": [[0.10546875]]}}, "model.layers.29.self_attn.o_proj": {"inputs": [[[0.46875]]], "outputs": [[[2.359375]], [[4.03568452807034e+29]]], "params": {"weight": [[0.2197265625]]}}, "model.layers.29.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.095545958979983e-15]], [[4.725109192804666e-13]]]}, "model.layers.29.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.625]]]}, "model.layers.29.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[676.0]]]}, "model.layers.29.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[128.0]]]}, "model.layers.29.self_attn.attn.impl.k_cache": {"inputs": [[[4.725109192804666e-13]]]}, "model.layers.29.self_attn.attn.impl.v_cache": {"inputs": [[[0.625]]]}, "model.layers.29.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[3.2152058793144533e-13]], [[4.725109192804666e-13]], [[0.58984375]]], "outputs": [[[0.46875]], [[1.0]]]}, "model.layers.29.mlp.gate_up_proj": {"inputs": [[[59.25]]], "params": {"weight": [[0.326171875]]}}, "model.layers.29.mlp.down_proj": {"inputs": [[[129.0]]], "outputs": [[[28.875]], [[4.03568452807034e+29]]], "params": {"weight": [[0.57421875]]}}, "model.layers.30.self_attn.qkv_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.30.self_attn.o_proj": {"inputs": [[[21.25]]], "outputs": [[[16.5]], [[6.698062947509928e+35]]], "params": {"weight": [[0.77734375]]}}, "model.layers.30.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51953125]], [[75.0]]]}, "model.layers.30.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[38.0]]]}, "model.layers.30.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[19.875]]]}, "model.layers.30.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[33.75]]]}, "model.layers.30.self_attn.attn.impl.k_cache": {"inputs": [[[75.0]]]}, "model.layers.30.self_attn.attn.impl.v_cache": {"inputs": [[[38.0]]]}, "model.layers.30.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.5]], [[75.0]], [[38.0]]], "outputs": [[[21.25]], [[1.0]]]}, "model.layers.30.mlp.gate_up_proj": {"inputs": [[[62.0]]], "params": {"weight": [[0.33984375]]}}, "model.layers.30.mlp.down_proj": {"inputs": [[[121.5]]], "outputs": [[[37.5]], [[6.698062947509928e+35]]], "params": {"weight": [[0.55078125]]}}, "model.layers.31.self_attn.qkv_proj": {"inputs": [[[169.0]]], "params": {"weight": [[0.265625]]}}, "model.layers.31.self_attn.o_proj": {"inputs": [[[18.625]]], "outputs": [[[37.25]], [[6.698062947509928e+35]]], "params": {"weight": [[0.326171875]]}}, "model.layers.31.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.53125]], [[73.0]]]}, "model.layers.31.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[22.5]]]}, "model.layers.31.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[40.25]]]}, "model.layers.31.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[22.5]]]}, "model.layers.31.self_attn.attn.impl.k_cache": {"inputs": [[[73.0]]]}, "model.layers.31.self_attn.attn.impl.v_cache": {"inputs": [[[22.5]]]}, "model.layers.31.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.5]], [[73.0]], [[22.5]]], "outputs": [[[18.625]], [[1.0]]]}, "model.layers.31.mlp.gate_up_proj": {"inputs": [[[63.75]]], "params": {"weight": [[0.302734375]]}}, "model.layers.31.mlp.down_proj": {"inputs": [[[176.0]]], "outputs": [[[28.125]], [[6.698062947509928e+35]]], "params": {"weight": [[0.451171875]]}}, "model.layers.32.self_attn.qkv_proj": {"inputs": [[[174.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.32.self_attn.o_proj": {"inputs": [[[24.125]]], "outputs": [[[47.0]], [[6.698062947509928e+35]]], "params": {"weight": [[0.75390625]]}}, "model.layers.32.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.6796875]], [[78.0]]]}, "model.layers.32.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[30.125]]]}, "model.layers.32.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[22.25]]]}, "model.layers.32.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.32.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.32.self_attn.attn.impl.v_cache": {"inputs": [[[30.125]]]}, "model.layers.32.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[96.0]], [[77.5]], [[30.125]]], "outputs": [[[24.125]], [[1.0]]]}, "model.layers.32.mlp.gate_up_proj": {"inputs": [[[68.5]]], "params": {"weight": [[0.43359375]]}}, "model.layers.32.mlp.down_proj": {"inputs": [[[196.0]]], "outputs": [[[49.75]], [[6.698062947509928e+35]]], "params": {"weight": [[0.4921875]]}}, "model.layers.33.self_attn.qkv_proj": {"inputs": [[[205.0]]], "params": {"weight": [[0.20703125]]}}, "model.layers.33.self_attn.o_proj": {"inputs": [[[27.75]]], "outputs": [[[34.25]], [[6.698062947509928e+35]]], "params": {"weight": [[0.47265625]]}}, "model.layers.33.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.55859375]], [[90.5]]]}, "model.layers.33.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[29.5]]]}, "model.layers.33.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[27.375]]]}, "model.layers.33.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[27.875]]]}, "model.layers.33.self_attn.attn.impl.k_cache": {"inputs": [[[90.5]]]}, "model.layers.33.self_attn.attn.impl.v_cache": {"inputs": [[[29.5]]]}, "model.layers.33.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[78.0]], [[90.5]], [[29.5]]], "outputs": [[[27.75]], [[1.0]]]}, "model.layers.33.mlp.gate_up_proj": {"inputs": [[[70.5]]], "params": {"weight": [[0.384765625]]}}, "model.layers.33.mlp.down_proj": {"inputs": [[[244.0]]], "outputs": [[[86.0]], [[6.698062947509928e+35]]], "params": {"weight": [[0.5234375]]}}, "model.layers.34.self_attn.qkv_proj": {"inputs": [[[178.0]]], "params": {"weight": [[0.310546875]]}}, "model.layers.34.self_attn.o_proj": {"inputs": [[[36.5]]], "outputs": [[[87.0]], [[2.3025684730708073e+29]]], "params": {"weight": [[0.353515625]]}}, "model.layers.34.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.51171875]], [[80.5]]]}, "model.layers.34.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[40.25]]]}, "model.layers.34.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[22.0]]]}, "model.layers.34.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[29.5]]]}, "model.layers.34.self_attn.attn.impl.k_cache": {"inputs": [[[80.5]]]}, "model.layers.34.self_attn.attn.impl.v_cache": {"inputs": [[[40.25]]]}, "model.layers.34.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[81.5]], [[80.5]], [[40.25]]], "outputs": [[[36.5]], [[1.0]]]}, "model.layers.34.mlp.gate_up_proj": {"inputs": [[[82.5]]], "params": {"weight": [[0.294921875]]}}, "model.layers.34.mlp.down_proj": {"inputs": [[[282.0]]], "outputs": [[[86.5]], [[2.3025684730708073e+29]]], "params": {"weight": [[0.4921875]]}}, "model.layers.35.self_attn.qkv_proj": {"inputs": [[[192.0]]], "params": {"weight": [[0.25]]}}, "model.layers.35.self_attn.o_proj": {"inputs": [[[29.25]]], "outputs": [[[55.75]], [[1.653887892485268e+30]]], "params": {"weight": [[0.451171875]]}}, "model.layers.35.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5546875]], [[85.5]]]}, "model.layers.35.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[32.25]]]}, "model.layers.35.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[28.75]]]}, "model.layers.35.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.0]]]}, "model.layers.35.self_attn.attn.impl.k_cache": {"inputs": [[[85.5]]]}, "model.layers.35.self_attn.attn.impl.v_cache": {"inputs": [[[32.25]]]}, "model.layers.35.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[75.5]], [[85.5]], [[31.375]]], "outputs": [[[29.25]], [[1.0]]]}, "model.layers.35.mlp.gate_up_proj": {"inputs": [[[105.0]]], "params": {"weight": [[0.3671875]]}}, "model.layers.35.mlp.down_proj": {"inputs": [[[292.0]]], "outputs": [[[108.0]], [[1.653887892485268e+30]]], "params": {"weight": [[0.5078125]]}}, "model.layers.36.self_attn.qkv_proj": {"inputs": [[[202.0]]], "params": {"weight": [[0.2353515625]]}}, "model.layers.36.self_attn.o_proj": {"inputs": [[[35.5]]], "outputs": [[[69.0]], [[7.081017024712375e+29]]], "params": {"weight": [[0.43359375]]}}, "model.layers.36.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5546875]], [[90.0]]]}, "model.layers.36.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[45.0]]]}, "model.layers.36.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[17.75]]]}, "model.layers.36.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[42.5]]]}, "model.layers.36.self_attn.attn.impl.k_cache": {"inputs": [[[90.0]]]}, "model.layers.36.self_attn.attn.impl.v_cache": {"inputs": [[[45.0]]]}, "model.layers.36.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[78.5]], [[90.0]], [[42.5]]], "outputs": [[[35.5]], [[1.0]]]}, "model.layers.36.mlp.gate_up_proj": {"inputs": [[[112.0]]], "params": {"weight": [[0.392578125]]}}, "model.layers.36.mlp.down_proj": {"inputs": [[[354.0]]], "outputs": [[[96.5]], [[7.081017024712375e+29]]], "params": {"weight": [[0.4921875]]}}, "model.layers.37.self_attn.qkv_proj": {"inputs": [[[217.0]]], "params": {"weight": [[0.234375]]}}, "model.layers.37.self_attn.o_proj": {"inputs": [[[47.0]]], "outputs": [[[70.5]], [[7.853348998533927e+34]]], "params": {"weight": [[0.41015625]]}}, "model.layers.37.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.7421875]], [[97.0]]]}, "model.layers.37.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[54.0]]]}, "model.layers.37.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[21.25]]]}, "model.layers.37.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[46.25]]]}, "model.layers.37.self_attn.attn.impl.k_cache": {"inputs": [[[97.0]]]}, "model.layers.37.self_attn.attn.impl.v_cache": {"inputs": [[[54.0]]]}, "model.layers.37.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[103.0]], [[97.0]], [[54.0]]], "outputs": [[[47.0]], [[1.0]]]}, "model.layers.37.mlp.gate_up_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.25390625]]}}, "model.layers.37.mlp.down_proj": {"inputs": [[[1400.0]]], "outputs": [[[780.0]], [[7.853348998533927e+34]]], "params": {"weight": [[0.54296875]]}}, "model.layers.38.self_attn.qkv_proj": {"inputs": [[[166.0]]], "params": {"weight": [[0.2001953125]]}}, "model.layers.38.self_attn.o_proj": {"inputs": [[[45.0]]], "outputs": [[[201.0]], [[7.431474878777972e+34]]], "params": {"weight": [[0.408203125]]}}, "model.layers.38.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5859375]], [[84.0]]]}, "model.layers.38.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[70.5]]]}, "model.layers.38.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.38.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[57.25]]]}, "model.layers.38.self_attn.attn.impl.k_cache": {"inputs": [[[84.0]]]}, "model.layers.38.self_attn.attn.impl.v_cache": {"inputs": [[[70.5]]]}, "model.layers.38.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[83.5]], [[84.0]], [[70.5]]], "outputs": [[[45.0]], [[1.0]]]}, "model.layers.38.mlp.gate_up_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.38.mlp.down_proj": {"inputs": [[[1192.0]]], "outputs": [[[636.0]], [[7.431474878777972e+34]]], "params": {"weight": [[0.41796875]]}}, "model.layers.39.self_attn.qkv_proj": {"inputs": [[[272.0]]], "params": {"weight": [[0.1904296875]]}}, "model.layers.39.self_attn.o_proj": {"inputs": [[[69.5]]], "outputs": [[[338.0]], [[7.431474878777972e+34]]], "params": {"weight": [[0.48046875]]}}, "model.layers.39.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.796875]], [[101.5]]]}, "model.layers.39.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[73.5]]]}, "model.layers.39.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.39.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[69.5]]]}, "model.layers.39.self_attn.attn.impl.k_cache": {"inputs": [[[101.5]]]}, "model.layers.39.self_attn.attn.impl.v_cache": {"inputs": [[[73.5]]]}, "model.layers.39.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[123.0]], [[101.5]], [[69.0]]], "outputs": [[[63.75]], [[1.0]]]}, "model.layers.39.mlp.gate_up_proj": {"inputs": [[[474.0]]], "params": {"weight": [[0.55078125]]}}, "model.layers.39.mlp.down_proj": {"inputs": [[[10176.0]]], "outputs": [[[13696.0]], [[7.431474878777972e+34]]], "params": {"weight": [[0.58984375]]}}, "lm_head": {"inputs": [[[1280.0]]], "params": {"weight": [[0.337890625]]}}}}