{"GlobalRank": null, "LocalRank": 0, "Mode": "DynamicRange", "Nodes": {"model.layers.0.self_attn.qkv_proj": {"inputs": [[[692.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.0.self_attn.o_proj": {"inputs": [[[35.0]]], "outputs": [[[34.75]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.546875]]}}, "model.layers.0.self_attn.attn.impl.matmul_qk": {"inputs": [[[1.21875]], [[200.0]]]}, "model.layers.0.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[62.25]]]}, "model.layers.0.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[1.21875]]]}, "model.layers.0.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[35.0]]]}, "model.layers.0.self_attn.attn.impl.k_cache": {"inputs": [[[200.0]]]}, "model.layers.0.self_attn.attn.impl.v_cache": {"inputs": [[[62.25]]]}, "model.layers.0.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[156.0]], [[200.0]], [[62.25]]], "outputs": [[[35.0]], [[1.0]]]}, "model.layers.0.mlp.gate_up_proj": {"inputs": [[[144.0]]], "params": {"weight": [[0.82421875]]}}, "model.layers.0.mlp.down_proj": {"inputs": [[[192.0]]], "outputs": [[[113.5]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.9453125]]}}, "model.layers.1.self_attn.qkv_proj": {"inputs": [[[164.0]]], "params": {"weight": [[0.466796875]]}}, "model.layers.1.self_attn.o_proj": {"inputs": [[[10.25]]], "outputs": [[[9.5625]], [[1.5551492463263744e+16]]], "params": {"weight": [[0.42578125]]}}, "model.layers.1.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.306640625]], [[118.0]]]}, "model.layers.1.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.6875]]]}, "model.layers.1.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.306640625]]]}, "model.layers.1.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.1.self_attn.attn.impl.k_cache": {"inputs": [[[118.0]]]}, "model.layers.1.self_attn.attn.impl.v_cache": {"inputs": [[[14.6875]]]}, "model.layers.1.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[41.25]], [[118.0]], [[13.625]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.1.mlp.gate_up_proj": {"inputs": [[[94.5]]], "params": {"weight": [[0.423828125]]}}, "model.layers.1.mlp.down_proj": {"inputs": [[[132.0]]], "outputs": [[[50.5]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.392578125]]}}, "model.layers.2.self_attn.qkv_proj": {"inputs": [[[117.0]]], "params": {"weight": [[0.408203125]]}}, "model.layers.2.self_attn.o_proj": {"inputs": [[[9.625]]], "outputs": [[[13.1875]], [[1.2137615228930877e+27]]], "params": {"weight": [[0.478515625]]}}, "model.layers.2.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.228515625]], [[83.5]]]}, "model.layers.2.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.2.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.228515625]]]}, "model.layers.2.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.9375]]]}, "model.layers.2.self_attn.attn.impl.k_cache": {"inputs": [[[83.5]]]}, "model.layers.2.self_attn.attn.impl.v_cache": {"inputs": [[[10.9375]]]}, "model.layers.2.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[30.625]], [[83.5]], [[10.9375]]], "outputs": [[[9.625]], [[1.0]]]}, "model.layers.2.mlp.gate_up_proj": {"inputs": [[[54.25]]], "params": {"weight": [[0.55078125]]}}, "model.layers.2.mlp.down_proj": {"inputs": [[[2688.0]]], "outputs": [[[1992.0]], [[4116571534393344.0]]], "params": {"weight": [[0.66796875]]}}, "model.layers.3.self_attn.qkv_proj": {"inputs": [[[108.5]]], "params": {"weight": [[0.4375]]}}, "model.layers.3.self_attn.o_proj": {"inputs": [[[9.5]]], "outputs": [[[6.90625]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.32421875]]}}, "model.layers.3.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.37109375]], [[78.5]]]}, "model.layers.3.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[11.1875]]]}, "model.layers.3.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.37109375]]]}, "model.layers.3.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[9.5625]]]}, "model.layers.3.self_attn.attn.impl.k_cache": {"inputs": [[[78.5]]]}, "model.layers.3.self_attn.attn.impl.v_cache": {"inputs": [[[11.1875]]]}, "model.layers.3.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.0]], [[78.5]], [[11.1875]]], "outputs": [[[9.5]], [[1.0]]]}, "model.layers.3.mlp.gate_up_proj": {"inputs": [[[21.75]]], "params": {"weight": [[0.251953125]]}}, "model.layers.3.mlp.down_proj": {"inputs": [[[76.5]]], "outputs": [[[89.0]], [[5.70612986858105e+26]]], "params": {"weight": [[0.5390625]]}}, "model.layers.4.self_attn.qkv_proj": {"inputs": [[[145.0]]], "params": {"weight": [[0.2021484375]]}}, "model.layers.4.self_attn.o_proj": {"inputs": [[[9.75]]], "outputs": [[[6.875]], [[4.0378122375128614e+26]]], "params": {"weight": [[0.359375]]}}, "model.layers.4.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.400390625]], [[76.5]]]}, "model.layers.4.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.375]]]}, "model.layers.4.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.400390625]]]}, "model.layers.4.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.25]]]}, "model.layers.4.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.4.self_attn.attn.impl.v_cache": {"inputs": [[[14.375]]]}, "model.layers.4.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.0]], [[76.5]], [[14.375]]], "outputs": [[[9.75]], [[1.0]]]}, "model.layers.4.mlp.gate_up_proj": {"inputs": [[[28.75]]], "params": {"weight": [[0.384765625]]}}, "model.layers.4.mlp.down_proj": {"inputs": [[[2144.0]]], "outputs": [[[2496.0]], [[4.0378122375128614e+26]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.qkv_proj": {"inputs": [[[177.0]]], "params": {"weight": [[0.59765625]]}}, "model.layers.5.self_attn.o_proj": {"inputs": [[[10.3125]]], "outputs": [[[11.5625]], [[4.642275147320176e+26]]], "params": {"weight": [[0.453125]]}}, "model.layers.5.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4140625]], [[72.5]]]}, "model.layers.5.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.4375]]]}, "model.layers.5.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.4140625]]]}, "model.layers.5.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[11.6875]]]}, "model.layers.5.self_attn.attn.impl.k_cache": {"inputs": [[[72.5]]]}, "model.layers.5.self_attn.attn.impl.v_cache": {"inputs": [[[15.4375]]]}, "model.layers.5.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[54.25]], [[72.5]], [[15.4375]]], "outputs": [[[10.3125]], [[1.0]]]}, "model.layers.5.mlp.gate_up_proj": {"inputs": [[[103.5]]], "params": {"weight": [[0.400390625]]}}, "model.layers.5.mlp.down_proj": {"inputs": [[[28032.0]]], "outputs": [[[22272.0]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.76171875]]}}, "model.layers.6.self_attn.qkv_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.6.self_attn.o_proj": {"inputs": [[[9.4375]]], "outputs": [[[17.25]], [[1.1621448766437018e+21]]], "params": {"weight": [[0.353515625]]}}, "model.layers.6.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.447265625]], [[72.5]]]}, "model.layers.6.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[24.0]]]}, "model.layers.6.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.447265625]]]}, "model.layers.6.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.5625]]]}, "model.layers.6.self_attn.attn.impl.k_cache": {"inputs": [[[72.5]]]}, "model.layers.6.self_attn.attn.impl.v_cache": {"inputs": [[[24.0]]]}, "model.layers.6.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[58.25]], [[72.5]], [[24.0]]], "outputs": [[[9.4375]], [[1.0]]]}, "model.layers.6.mlp.gate_up_proj": {"inputs": [[[52.75]]], "params": {"weight": [[0.314453125]]}}, "model.layers.6.mlp.down_proj": {"inputs": [[[49.25]]], "outputs": [[[24.5]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.44140625]]}}, "model.layers.7.self_attn.qkv_proj": {"inputs": [[[153.0]]], "params": {"weight": [[0.22265625]]}}, "model.layers.7.self_attn.o_proj": {"inputs": [[[9.25]]], "outputs": [[[12.6875]], [[2.865154192486671e+26]]], "params": {"weight": [[0.48828125]]}}, "model.layers.7.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.431640625]], [[66.0]]]}, "model.layers.7.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.0625]]]}, "model.layers.7.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.431640625]]]}, "model.layers.7.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.125]]]}, "model.layers.7.self_attn.attn.impl.k_cache": {"inputs": [[[66.0]]]}, "model.layers.7.self_attn.attn.impl.v_cache": {"inputs": [[[12.0625]]]}, "model.layers.7.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.25]], [[66.0]], [[12.0625]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.7.mlp.gate_up_proj": {"inputs": [[[33.5]]], "params": {"weight": [[0.3125]]}}, "model.layers.7.mlp.down_proj": {"inputs": [[[60.5]]], "outputs": [[[20.75]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.5]]}}, "model.layers.8.self_attn.qkv_proj": {"inputs": [[[208.0]]], "params": {"weight": [[0.2041015625]]}}, "model.layers.8.self_attn.o_proj": {"inputs": [[[8.4375]]], "outputs": [[[12.875]], [[8409064929230848.0]]], "params": {"weight": [[0.43359375]]}}, "model.layers.8.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.439453125]], [[72.5]]]}, "model.layers.8.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.375]]]}, "model.layers.8.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.439453125]]]}, "model.layers.8.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[11.5625]]]}, "model.layers.8.self_attn.attn.impl.k_cache": {"inputs": [[[72.5]]]}, "model.layers.8.self_attn.attn.impl.v_cache": {"inputs": [[[14.375]]]}, "model.layers.8.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[65.5]], [[72.5]], [[14.375]]], "outputs": [[[8.4375]], [[1.0]]]}, "model.layers.8.mlp.gate_up_proj": {"inputs": [[[29.0]]], "params": {"weight": [[0.28515625]]}}, "model.layers.8.mlp.down_proj": {"inputs": [[[42.25]]], "outputs": [[[14.4375]], [[6.479842393134412e+26]]], "params": {"weight": [[0.58203125]]}}, "model.layers.9.self_attn.qkv_proj": {"inputs": [[[206.0]]], "params": {"weight": [[0.302734375]]}}, "model.layers.9.self_attn.o_proj": {"inputs": [[[9.25]]], "outputs": [[[12.5625]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.333984375]]}}, "model.layers.9.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.453125]], [[74.0]]]}, "model.layers.9.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.3125]]]}, "model.layers.9.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.453125]]]}, "model.layers.9.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[9.25]]]}, "model.layers.9.self_attn.attn.impl.k_cache": {"inputs": [[[74.0]]]}, "model.layers.9.self_attn.attn.impl.v_cache": {"inputs": [[[12.3125]]]}, "model.layers.9.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[74.0]], [[12.3125]]], "outputs": [[[9.25]], [[1.0]]]}, "model.layers.9.mlp.gate_up_proj": {"inputs": [[[26.0]]], "params": {"weight": [[0.3359375]]}}, "model.layers.9.mlp.down_proj": {"inputs": [[[34.25]]], "outputs": [[[17.875]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.5390625]]}}, "model.layers.10.self_attn.qkv_proj": {"inputs": [[[218.0]]], "params": {"weight": [[0.267578125]]}}, "model.layers.10.self_attn.o_proj": {"inputs": [[[11.5]]], "outputs": [[[14.75]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.54296875]]}}, "model.layers.10.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.462890625]], [[76.5]]]}, "model.layers.10.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[12.75]]]}, "model.layers.10.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.462890625]]]}, "model.layers.10.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[9.0625]]]}, "model.layers.10.self_attn.attn.impl.k_cache": {"inputs": [[[76.5]]]}, "model.layers.10.self_attn.attn.impl.v_cache": {"inputs": [[[12.75]]]}, "model.layers.10.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[69.5]], [[76.5]], [[12.75]]], "outputs": [[[11.5]], [[1.0]]]}, "model.layers.10.mlp.gate_up_proj": {"inputs": [[[25.875]]], "params": {"weight": [[0.341796875]]}}, "model.layers.10.mlp.down_proj": {"inputs": [[[34.5]]], "outputs": [[[17.875]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.57421875]]}}, "model.layers.11.self_attn.qkv_proj": {"inputs": [[[250.0]]], "params": {"weight": [[0.28125]]}}, "model.layers.11.self_attn.o_proj": {"inputs": [[[12.4375]]], "outputs": [[[15.375]], [[1.7166746638527734e+26]]], "params": {"weight": [[0.359375]]}}, "model.layers.11.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4296875]], [[81.5]]]}, "model.layers.11.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.3125]]]}, "model.layers.11.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.4296875]]]}, "model.layers.11.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.625]]]}, "model.layers.11.self_attn.attn.impl.k_cache": {"inputs": [[[81.5]]]}, "model.layers.11.self_attn.attn.impl.v_cache": {"inputs": [[[15.3125]]]}, "model.layers.11.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[70.5]], [[79.5]], [[15.3125]]], "outputs": [[[11.25]], [[1.0]]]}, "model.layers.11.mlp.gate_up_proj": {"inputs": [[[26.5]]], "params": {"weight": [[0.349609375]]}}, "model.layers.11.mlp.down_proj": {"inputs": [[[42.25]]], "outputs": [[[18.125]], [[1.2137615228930877e+27]]], "params": {"weight": [[0.443359375]]}}, "model.layers.12.self_attn.qkv_proj": {"inputs": [[[322.0]]], "params": {"weight": [[0.2734375]]}}, "model.layers.12.self_attn.o_proj": {"inputs": [[[11.0625]]], "outputs": [[[12.875]], [[5.70612986858105e+26]]], "params": {"weight": [[0.431640625]]}}, "model.layers.12.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.44921875]], [[75.5]]]}, "model.layers.12.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.5]]]}, "model.layers.12.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.44921875]]]}, "model.layers.12.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[9.5625]]]}, "model.layers.12.self_attn.attn.impl.k_cache": {"inputs": [[[75.5]]]}, "model.layers.12.self_attn.attn.impl.v_cache": {"inputs": [[[13.5]]]}, "model.layers.12.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[59.0]], [[75.5]], [[13.5]]], "outputs": [[[11.0625]], [[1.0]]]}, "model.layers.12.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.345703125]]}}, "model.layers.12.mlp.down_proj": {"inputs": [[[38.25]]], "outputs": [[[22.25]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.482421875]]}}, "model.layers.13.self_attn.qkv_proj": {"inputs": [[[248.0]]], "params": {"weight": [[0.353515625]]}}, "model.layers.13.self_attn.o_proj": {"inputs": [[[10.125]]], "outputs": [[[16.625]], [[6.479842393134412e+26]]], "params": {"weight": [[0.71875]]}}, "model.layers.13.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.482421875]], [[78.5]]]}, "model.layers.13.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[14.125]]]}, "model.layers.13.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.482421875]]]}, "model.layers.13.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.25]]]}, "model.layers.13.self_attn.attn.impl.k_cache": {"inputs": [[[78.5]]]}, "model.layers.13.self_attn.attn.impl.v_cache": {"inputs": [[[14.125]]]}, "model.layers.13.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.0]], [[78.5]], [[14.125]]], "outputs": [[[10.125]], [[1.0]]]}, "model.layers.13.mlp.gate_up_proj": {"inputs": [[[27.125]]], "params": {"weight": [[0.27734375]]}}, "model.layers.13.mlp.down_proj": {"inputs": [[[29.125]]], "outputs": [[[25.25]], [[1.2082617368279756e+21]]], "params": {"weight": [[0.56640625]]}}, "model.layers.14.self_attn.qkv_proj": {"inputs": [[[244.0]]], "params": {"weight": [[0.1708984375]]}}, "model.layers.14.self_attn.o_proj": {"inputs": [[[12.25]]], "outputs": [[[21.625]], [[1.558749874228457e+21]]], "params": {"weight": [[0.70703125]]}}, "model.layers.14.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.3984375]], [[78.0]]]}, "model.layers.14.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[30.0]]]}, "model.layers.14.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.3984375]]]}, "model.layers.14.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[14.125]]]}, "model.layers.14.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.14.self_attn.attn.impl.v_cache": {"inputs": [[[30.0]]]}, "model.layers.14.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[55.75]], [[78.0]], [[30.0]]], "outputs": [[[12.25]], [[1.0]]]}, "model.layers.14.mlp.gate_up_proj": {"inputs": [[[29.125]]], "params": {"weight": [[0.28125]]}}, "model.layers.14.mlp.down_proj": {"inputs": [[[46.5]]], "outputs": [[[40.5]], [[2.7563508687213545e+26]]], "params": {"weight": [[0.6015625]]}}, "model.layers.15.self_attn.qkv_proj": {"inputs": [[[214.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.15.self_attn.o_proj": {"inputs": [[[11.0625]]], "outputs": [[[33.5]], [[1.7524406870024074e+21]]], "params": {"weight": [[0.486328125]]}}, "model.layers.15.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.376953125]], [[94.5]]]}, "model.layers.15.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.0625]]]}, "model.layers.15.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.376953125]]]}, "model.layers.15.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.6875]]]}, "model.layers.15.self_attn.attn.impl.k_cache": {"inputs": [[[94.5]]]}, "model.layers.15.self_attn.attn.impl.v_cache": {"inputs": [[[15.0625]]]}, "model.layers.15.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[49.25]], [[86.5]], [[15.0625]]], "outputs": [[[11.0625]], [[1.0]]]}, "model.layers.15.mlp.gate_up_proj": {"inputs": [[[27.375]]], "params": {"weight": [[0.328125]]}}, "model.layers.15.mlp.down_proj": {"inputs": [[[35.5]]], "outputs": [[[51.5]], [[5.70612986858105e+26]]], "params": {"weight": [[0.640625]]}}, "model.layers.16.self_attn.qkv_proj": {"inputs": [[[190.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.16.self_attn.o_proj": {"inputs": [[[12.1875]]], "outputs": [[[35.5]], [[1.946370569579553e+26]]], "params": {"weight": [[0.41015625]]}}, "model.layers.16.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.4140625]], [[87.5]]]}, "model.layers.16.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[16.5]]]}, "model.layers.16.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.4140625]]]}, "model.layers.16.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[11.75]]]}, "model.layers.16.self_attn.attn.impl.k_cache": {"inputs": [[[87.5]]]}, "model.layers.16.self_attn.attn.impl.v_cache": {"inputs": [[[16.5]]]}, "model.layers.16.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[57.75]], [[87.5]], [[16.5]]], "outputs": [[[12.1875]], [[1.0]]]}, "model.layers.16.mlp.gate_up_proj": {"inputs": [[[30.375]]], "params": {"weight": [[0.30859375]]}}, "model.layers.16.mlp.down_proj": {"inputs": [[[44.0]]], "outputs": [[[37.0]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.6875]]}}, "model.layers.17.self_attn.qkv_proj": {"inputs": [[[192.0]]], "params": {"weight": [[0.1767578125]]}}, "model.layers.17.self_attn.o_proj": {"inputs": [[[12.3125]]], "outputs": [[[32.5]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.37890625]]}}, "model.layers.17.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.44921875]], [[80.0]]]}, "model.layers.17.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[13.6875]]]}, "model.layers.17.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.44921875]]]}, "model.layers.17.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[10.5]]]}, "model.layers.17.self_attn.attn.impl.k_cache": {"inputs": [[[80.0]]]}, "model.layers.17.self_attn.attn.impl.v_cache": {"inputs": [[[13.6875]]]}, "model.layers.17.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[61.0]], [[80.0]], [[13.6875]]], "outputs": [[[12.3125]], [[1.0]]]}, "model.layers.17.mlp.gate_up_proj": {"inputs": [[[31.75]]], "params": {"weight": [[0.298828125]]}}, "model.layers.17.mlp.down_proj": {"inputs": [[[59.0]]], "outputs": [[[26.75]], [[5.70612986858105e+26]]], "params": {"weight": [[0.62890625]]}}, "model.layers.18.self_attn.qkv_proj": {"inputs": [[[153.0]]], "params": {"weight": [[0.189453125]]}}, "model.layers.18.self_attn.o_proj": {"inputs": [[[15.0625]]], "outputs": [[[15.6875]], [[1.5034096420073285e+21]]], "params": {"weight": [[0.2578125]]}}, "model.layers.18.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.47265625]], [[75.5]]]}, "model.layers.18.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[18.25]]]}, "model.layers.18.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.47265625]]]}, "model.layers.18.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.0]]]}, "model.layers.18.self_attn.attn.impl.k_cache": {"inputs": [[[75.5]]]}, "model.layers.18.self_attn.attn.impl.v_cache": {"inputs": [[[18.25]]]}, "model.layers.18.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[63.75]], [[75.5]], [[18.25]]], "outputs": [[[15.0625]], [[1.0]]]}, "model.layers.18.mlp.gate_up_proj": {"inputs": [[[31.625]]], "params": {"weight": [[0.330078125]]}}, "model.layers.18.mlp.down_proj": {"inputs": [[[61.75]]], "outputs": [[[45.0]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.625]]}}, "model.layers.19.self_attn.qkv_proj": {"inputs": [[[154.0]]], "params": {"weight": [[0.1884765625]]}}, "model.layers.19.self_attn.o_proj": {"inputs": [[[14.25]]], "outputs": [[[39.5]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.40625]]}}, "model.layers.19.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.48046875]], [[86.5]]]}, "model.layers.19.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[23.625]]]}, "model.layers.19.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.48046875]]]}, "model.layers.19.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[11.4375]]]}, "model.layers.19.self_attn.attn.impl.k_cache": {"inputs": [[[86.5]]]}, "model.layers.19.self_attn.attn.impl.v_cache": {"inputs": [[[23.625]]]}, "model.layers.19.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[62.75]], [[86.5]], [[23.625]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.19.mlp.gate_up_proj": {"inputs": [[[37.0]]], "params": {"weight": [[0.52734375]]}}, "model.layers.19.mlp.down_proj": {"inputs": [[[376.0]]], "outputs": [[[107.5]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.67578125]]}}, "model.layers.20.self_attn.qkv_proj": {"inputs": [[[0.78515625]]], "params": {"weight": [[0.07275390625]]}}, "model.layers.20.self_attn.o_proj": {"inputs": [[[0.138671875]]], "outputs": [[[0.419921875]], [[4.0378122375128614e+26]]], "params": {"weight": [[0.27734375]]}}, "model.layers.20.self_attn.attn.impl.matmul_qk": {"inputs": [[[6.83481049534862e-16]], [[1.1901590823981678e-13]]]}, "model.layers.20.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.287109375]]]}, "model.layers.20.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[6.83481049534862e-16]]]}, "model.layers.20.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.2060546875]]]}, "model.layers.20.self_attn.attn.impl.k_cache": {"inputs": [[[1.1901590823981678e-13]]]}, "model.layers.20.self_attn.attn.impl.v_cache": {"inputs": [[[0.287109375]]]}, "model.layers.20.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.0391687510491465e-13]], [[1.1901590823981678e-13]], [[0.287109375]]], "outputs": [[[0.138671875]], [[1.0]]]}, "model.layers.20.mlp.gate_up_proj": {"inputs": [[[35.25]]], "params": {"weight": [[0.388671875]]}}, "model.layers.20.mlp.down_proj": {"inputs": [[[77.0]]], "outputs": [[[31.625]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.69140625]]}}, "model.layers.21.self_attn.qkv_proj": {"inputs": [[[158.0]]], "params": {"weight": [[0.166015625]]}}, "model.layers.21.self_attn.o_proj": {"inputs": [[[14.25]]], "outputs": [[[36.0]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.4609375]]}}, "model.layers.21.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.52734375]], [[73.5]]]}, "model.layers.21.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[20.5]]]}, "model.layers.21.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.52734375]]]}, "model.layers.21.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.625]]]}, "model.layers.21.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.21.self_attn.attn.impl.v_cache": {"inputs": [[[20.5]]]}, "model.layers.21.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[73.5]], [[73.5]], [[20.5]]], "outputs": [[[14.25]], [[1.0]]]}, "model.layers.21.mlp.gate_up_proj": {"inputs": [[[39.75]]], "params": {"weight": [[0.37890625]]}}, "model.layers.21.mlp.down_proj": {"inputs": [[[75.0]]], "outputs": [[[21.25]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.56640625]]}}, "model.layers.22.self_attn.qkv_proj": {"inputs": [[[162.0]]], "params": {"weight": [[0.154296875]]}}, "model.layers.22.self_attn.o_proj": {"inputs": [[[10.6875]]], "outputs": [[[12.6875]], [[2.865154192486671e+26]]], "params": {"weight": [[0.28515625]]}}, "model.layers.22.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.53125]], [[72.0]]]}, "model.layers.22.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[17.0]]]}, "model.layers.22.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.53125]]]}, "model.layers.22.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[12.25]]]}, "model.layers.22.self_attn.attn.impl.k_cache": {"inputs": [[[72.0]]]}, "model.layers.22.self_attn.attn.impl.v_cache": {"inputs": [[[17.0]]]}, "model.layers.22.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[71.5]], [[72.0]], [[17.0]]], "outputs": [[[10.25]], [[1.0]]]}, "model.layers.22.mlp.gate_up_proj": {"inputs": [[[41.75]]], "params": {"weight": [[0.208984375]]}}, "model.layers.22.mlp.down_proj": {"inputs": [[[106.0]]], "outputs": [[[33.25]], [[2.030995376952577e+26]]], "params": {"weight": [[0.578125]]}}, "model.layers.23.self_attn.qkv_proj": {"inputs": [[[1.109375]]], "params": {"weight": [[0.04541015625]]}}, "model.layers.23.self_attn.o_proj": {"inputs": [[[0.06640625]]], "outputs": [[[0.130859375]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.11865234375]]}}, "model.layers.23.self_attn.attn.impl.matmul_qk": {"inputs": [[[5.30825383648903e-16]], [[1.0258460747536446e-13]]]}, "model.layers.23.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.1748046875]]]}, "model.layers.23.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[5.30825383648903e-16]]]}, "model.layers.23.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.1474609375]]]}, "model.layers.23.self_attn.attn.impl.k_cache": {"inputs": [[[1.0258460747536446e-13]]]}, "model.layers.23.self_attn.attn.impl.v_cache": {"inputs": [[[0.1748046875]]]}, "model.layers.23.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.72715225139109e-14]], [[1.0258460747536446e-13]], [[0.1748046875]]], "outputs": [[[0.06640625]], [[1.0]]]}, "model.layers.23.mlp.gate_up_proj": {"inputs": [[[43.75]]], "params": {"weight": [[0.3515625]]}}, "model.layers.23.mlp.down_proj": {"inputs": [[[115.0]]], "outputs": [[[13.0625]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.484375]]}}, "model.layers.24.self_attn.qkv_proj": {"inputs": [[[1.0625]]], "params": {"weight": [[0.044189453125]]}}, "model.layers.24.self_attn.o_proj": {"inputs": [[[0.0615234375]]], "outputs": [[[0.279296875]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.1181640625]]}}, "model.layers.24.self_attn.attn.impl.matmul_qk": {"inputs": [[[5.204170427930421e-16]], [[8.038014698286133e-14]]]}, "model.layers.24.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[5.204170427930421e-16]]]}, "model.layers.24.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.1552734375]]]}, "model.layers.24.self_attn.attn.impl.k_cache": {"inputs": [[[8.038014698286133e-14]]]}, "model.layers.24.self_attn.attn.impl.v_cache": {"inputs": [[[0.197265625]]]}, "model.layers.24.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[7.638334409421077e-14]], [[8.038014698286133e-14]], [[0.197265625]]], "outputs": [[[0.0615234375]], [[1.0]]]}, "model.layers.24.mlp.gate_up_proj": {"inputs": [[[43.25]]], "params": {"weight": [[0.2333984375]]}}, "model.layers.24.mlp.down_proj": {"inputs": [[[85.0]]], "outputs": [[[14.75]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.48828125]]}}, "model.layers.25.self_attn.qkv_proj": {"inputs": [[[174.0]]], "params": {"weight": [[0.220703125]]}}, "model.layers.25.self_attn.o_proj": {"inputs": [[[10.9375]]], "outputs": [[[9.5]], [[4609152743636992.0]]], "params": {"weight": [[0.38671875]]}}, "model.layers.25.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.578125]], [[72.5]]]}, "model.layers.25.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[15.375]]]}, "model.layers.25.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.578125]]]}, "model.layers.25.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[11.375]]]}, "model.layers.25.self_attn.attn.impl.k_cache": {"inputs": [[[72.5]]]}, "model.layers.25.self_attn.attn.impl.v_cache": {"inputs": [[[15.375]]]}, "model.layers.25.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[79.5]], [[72.0]], [[15.375]]], "outputs": [[[10.9375]], [[1.0]]]}, "model.layers.25.mlp.gate_up_proj": {"inputs": [[[47.75]]], "params": {"weight": [[0.28515625]]}}, "model.layers.25.mlp.down_proj": {"inputs": [[[113.5]]], "outputs": [[[29.75]], [[4.30377591782808e+26]]], "params": {"weight": [[0.61328125]]}}, "model.layers.26.self_attn.qkv_proj": {"inputs": [[[1.65625]]], "params": {"weight": [[0.058349609375]]}}, "model.layers.26.self_attn.o_proj": {"inputs": [[[0.08544921875]]], "outputs": [[[0.2001953125]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.166015625]]}}, "model.layers.26.self_attn.attn.impl.matmul_qk": {"inputs": [[[6.38378239159465e-16]], [[1.0746958878371515e-13]]]}, "model.layers.26.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[6.38378239159465e-16]]]}, "model.layers.26.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.1884765625]]]}, "model.layers.26.self_attn.attn.impl.k_cache": {"inputs": [[[1.0746958878371515e-13]]]}, "model.layers.26.self_attn.attn.impl.v_cache": {"inputs": [[[0.28515625]]]}, "model.layers.26.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[9.50350909079134e-14]], [[1.0746958878371515e-13]], [[0.28515625]]], "outputs": [[[0.08544921875]], [[1.0]]]}, "model.layers.26.mlp.gate_up_proj": {"inputs": [[[55.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.26.mlp.down_proj": {"inputs": [[[336.0]]], "outputs": [[[102.0]], [[9.730657498881788e+20]]], "params": {"weight": [[0.419921875]]}}, "model.layers.27.self_attn.qkv_proj": {"inputs": [[[1.734375]]], "params": {"weight": [[0.06689453125]]}}, "model.layers.27.self_attn.o_proj": {"inputs": [[[0.126953125]]], "outputs": [[[0.384765625]], [[4.0378122375128614e+26]]], "params": {"weight": [[0.1640625]]}}, "model.layers.27.self_attn.attn.impl.matmul_qk": {"inputs": [[[7.28583859910259e-16]], [[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.283203125]]]}, "model.layers.27.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[7.28583859910259e-16]]]}, "model.layers.27.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.2294921875]]]}, "model.layers.27.self_attn.attn.impl.k_cache": {"inputs": [[[1.412203687323199e-13]]]}, "model.layers.27.self_attn.attn.impl.v_cache": {"inputs": [[[0.283203125]]]}, "model.layers.27.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[1.2079226507921703e-13]], [[1.412203687323199e-13]], [[0.283203125]]], "outputs": [[[0.126953125]], [[1.0]]]}, "model.layers.27.mlp.gate_up_proj": {"inputs": [[[62.5]]], "params": {"weight": [[0.6640625]]}}, "model.layers.27.mlp.down_proj": {"inputs": [[[156.0]]], "outputs": [[[17.875]], [[1.7166746638527734e+26]]], "params": {"weight": [[0.5546875]]}}, "model.layers.28.self_attn.qkv_proj": {"inputs": [[[168.0]]], "params": {"weight": [[0.228515625]]}}, "model.layers.28.self_attn.o_proj": {"inputs": [[[14.875]]], "outputs": [[[9.4375]], [[1.7166746638527734e+26]]], "params": {"weight": [[0.87109375]]}}, "model.layers.28.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5234375]], [[73.5]]]}, "model.layers.28.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[25.25]]]}, "model.layers.28.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.5234375]]]}, "model.layers.28.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[21.0]]]}, "model.layers.28.self_attn.attn.impl.k_cache": {"inputs": [[[73.5]]]}, "model.layers.28.self_attn.attn.impl.v_cache": {"inputs": [[[25.25]]]}, "model.layers.28.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[67.5]], [[72.0]], [[25.25]]], "outputs": [[[14.875]], [[1.0]]]}, "model.layers.28.mlp.gate_up_proj": {"inputs": [[[56.5]]], "params": {"weight": [[0.2451171875]]}}, "model.layers.28.mlp.down_proj": {"inputs": [[[149.0]]], "outputs": [[[32.25]], [[7.00976274800963e+21]]], "params": {"weight": [[0.5859375]]}}, "model.layers.29.self_attn.qkv_proj": {"inputs": [[[5.53125]]], "params": {"weight": [[0.10546875]]}}, "model.layers.29.self_attn.o_proj": {"inputs": [[[0.46875]]], "outputs": [[[2.359375]], [[2.2244235080909177e+26]]], "params": {"weight": [[0.2197265625]]}}, "model.layers.29.self_attn.attn.impl.matmul_qk": {"inputs": [[[2.1788126858268697e-15]], [[4.760636329592671e-13]]]}, "model.layers.29.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[0.5859375]]]}, "model.layers.29.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[2.1788126858268697e-15]]]}, "model.layers.29.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[0.466796875]]]}, "model.layers.29.self_attn.attn.impl.k_cache": {"inputs": [[[4.760636329592671e-13]]]}, "model.layers.29.self_attn.attn.impl.v_cache": {"inputs": [[[0.5859375]]]}, "model.layers.29.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[3.197442310920451e-13]], [[4.760636329592671e-13]], [[0.5859375]]], "outputs": [[[0.46875]], [[1.0]]]}, "model.layers.29.mlp.gate_up_proj": {"inputs": [[[59.25]]], "params": {"weight": [[0.326171875]]}}, "model.layers.29.mlp.down_proj": {"inputs": [[[131.0]]], "outputs": [[[29.375]], [[7.101996468378177e+20]]], "params": {"weight": [[0.57421875]]}}, "model.layers.30.self_attn.qkv_proj": {"inputs": [[[176.0]]], "params": {"weight": [[0.193359375]]}}, "model.layers.30.self_attn.o_proj": {"inputs": [[[21.375]]], "outputs": [[[16.625]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.77734375]]}}, "model.layers.30.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.515625]], [[75.0]]]}, "model.layers.30.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[38.0]]]}, "model.layers.30.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.515625]]]}, "model.layers.30.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[33.75]]]}, "model.layers.30.self_attn.attn.impl.k_cache": {"inputs": [[[75.0]]]}, "model.layers.30.self_attn.attn.impl.v_cache": {"inputs": [[[38.0]]]}, "model.layers.30.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[68.5]], [[75.0]], [[38.0]]], "outputs": [[[21.375]], [[1.0]]]}, "model.layers.30.mlp.gate_up_proj": {"inputs": [[[62.0]]], "params": {"weight": [[0.33984375]]}}, "model.layers.30.mlp.down_proj": {"inputs": [[[122.5]]], "outputs": [[[37.5]], [[5.70612986858105e+26]]], "params": {"weight": [[0.55078125]]}}, "model.layers.31.self_attn.qkv_proj": {"inputs": [[[169.0]]], "params": {"weight": [[0.265625]]}}, "model.layers.31.self_attn.o_proj": {"inputs": [[[18.625]]], "outputs": [[[38.5]], [[5.70612986858105e+26]]], "params": {"weight": [[0.326171875]]}}, "model.layers.31.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.53125]], [[73.0]]]}, "model.layers.31.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[22.5]]]}, "model.layers.31.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.53125]]]}, "model.layers.31.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[18.75]]]}, "model.layers.31.self_attn.attn.impl.k_cache": {"inputs": [[[73.0]]]}, "model.layers.31.self_attn.attn.impl.v_cache": {"inputs": [[[22.5]]]}, "model.layers.31.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[74.5]], [[73.0]], [[22.5]]], "outputs": [[[18.625]], [[1.0]]]}, "model.layers.31.mlp.gate_up_proj": {"inputs": [[[63.75]]], "params": {"weight": [[0.302734375]]}}, "model.layers.31.mlp.down_proj": {"inputs": [[[176.0]]], "outputs": [[[27.875]], [[5.70612986858105e+26]]], "params": {"weight": [[0.451171875]]}}, "model.layers.32.self_attn.qkv_proj": {"inputs": [[[175.0]]], "params": {"weight": [[0.259765625]]}}, "model.layers.32.self_attn.o_proj": {"inputs": [[[23.375]]], "outputs": [[[47.25]], [[2.865154192486671e+26]]], "params": {"weight": [[0.75390625]]}}, "model.layers.32.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.671875]], [[78.0]]]}, "model.layers.32.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[30.125]]]}, "model.layers.32.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.671875]]]}, "model.layers.32.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[20.375]]]}, "model.layers.32.self_attn.attn.impl.k_cache": {"inputs": [[[78.0]]]}, "model.layers.32.self_attn.attn.impl.v_cache": {"inputs": [[[30.125]]]}, "model.layers.32.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[96.5]], [[78.0]], [[30.125]]], "outputs": [[[23.375]], [[1.0]]]}, "model.layers.32.mlp.gate_up_proj": {"inputs": [[[68.5]]], "params": {"weight": [[0.43359375]]}}, "model.layers.32.mlp.down_proj": {"inputs": [[[194.0]]], "outputs": [[[49.5]], [[4.642275147320176e+26]]], "params": {"weight": [[0.4921875]]}}, "model.layers.33.self_attn.qkv_proj": {"inputs": [[[209.0]]], "params": {"weight": [[0.20703125]]}}, "model.layers.33.self_attn.o_proj": {"inputs": [[[27.625]]], "outputs": [[[34.0]], [[1.1847473032223366e+26]]], "params": {"weight": [[0.47265625]]}}, "model.layers.33.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5703125]], [[90.5]]]}, "model.layers.33.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[29.5]]]}, "model.layers.33.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.5703125]]]}, "model.layers.33.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[27.625]]]}, "model.layers.33.self_attn.attn.impl.k_cache": {"inputs": [[[90.5]]]}, "model.layers.33.self_attn.attn.impl.v_cache": {"inputs": [[[29.5]]]}, "model.layers.33.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[77.5]], [[90.5]], [[29.5]]], "outputs": [[[27.625]], [[1.0]]]}, "model.layers.33.mlp.gate_up_proj": {"inputs": [[[70.5]]], "params": {"weight": [[0.384765625]]}}, "model.layers.33.mlp.down_proj": {"inputs": [[[244.0]]], "outputs": [[[86.0]], [[5.70612986858105e+26]]], "params": {"weight": [[0.5234375]]}}, "model.layers.34.self_attn.qkv_proj": {"inputs": [[[191.0]]], "params": {"weight": [[0.310546875]]}}, "model.layers.34.self_attn.o_proj": {"inputs": [[[36.0]]], "outputs": [[[87.0]], [[1.062849512059437e+18]]], "params": {"weight": [[0.353515625]]}}, "model.layers.34.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.55859375]], [[80.5]]]}, "model.layers.34.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[41.0]]]}, "model.layers.34.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.55859375]]]}, "model.layers.34.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[29.375]]]}, "model.layers.34.self_attn.attn.impl.k_cache": {"inputs": [[[80.5]]]}, "model.layers.34.self_attn.attn.impl.v_cache": {"inputs": [[[41.0]]]}, "model.layers.34.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[81.5]], [[80.5]], [[41.0]]], "outputs": [[[36.0]], [[1.0]]]}, "model.layers.34.mlp.gate_up_proj": {"inputs": [[[82.5]]], "params": {"weight": [[0.294921875]]}}, "model.layers.34.mlp.down_proj": {"inputs": [[[290.0]]], "outputs": [[[86.5]], [[2.1859391727345819e+21]]], "params": {"weight": [[0.4921875]]}}, "model.layers.35.self_attn.qkv_proj": {"inputs": [[[194.0]]], "params": {"weight": [[0.25]]}}, "model.layers.35.self_attn.o_proj": {"inputs": [[[28.625]]], "outputs": [[[56.25]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.451171875]]}}, "model.layers.35.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5703125]], [[85.5]]]}, "model.layers.35.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[32.5]]]}, "model.layers.35.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.5703125]]]}, "model.layers.35.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[25.125]]]}, "model.layers.35.self_attn.attn.impl.k_cache": {"inputs": [[[85.5]]]}, "model.layers.35.self_attn.attn.impl.v_cache": {"inputs": [[[32.5]]]}, "model.layers.35.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[75.0]], [[85.5]], [[30.875]]], "outputs": [[[28.625]], [[1.0]]]}, "model.layers.35.mlp.gate_up_proj": {"inputs": [[[105.0]]], "params": {"weight": [[0.3671875]]}}, "model.layers.35.mlp.down_proj": {"inputs": [[[294.0]]], "outputs": [[[108.0]], [[1.1303456413396783e+26]]], "params": {"weight": [[0.5078125]]}}, "model.layers.36.self_attn.qkv_proj": {"inputs": [[[202.0]]], "params": {"weight": [[0.2353515625]]}}, "model.layers.36.self_attn.o_proj": {"inputs": [[[35.5]]], "outputs": [[[69.0]], [[2.865154192486671e+26]]], "params": {"weight": [[0.43359375]]}}, "model.layers.36.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.5546875]], [[90.0]]]}, "model.layers.36.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[43.25]]]}, "model.layers.36.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.5546875]]]}, "model.layers.36.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[42.5]]]}, "model.layers.36.self_attn.attn.impl.k_cache": {"inputs": [[[90.0]]]}, "model.layers.36.self_attn.attn.impl.v_cache": {"inputs": [[[43.25]]]}, "model.layers.36.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[79.0]], [[90.0]], [[42.5]]], "outputs": [[[35.5]], [[1.0]]]}, "model.layers.36.mlp.gate_up_proj": {"inputs": [[[112.0]]], "params": {"weight": [[0.392578125]]}}, "model.layers.36.mlp.down_proj": {"inputs": [[[352.0]]], "outputs": [[[96.0]], [[2.7563508687213545e+26]]], "params": {"weight": [[0.4921875]]}}, "model.layers.37.self_attn.qkv_proj": {"inputs": [[[218.0]]], "params": {"weight": [[0.234375]]}}, "model.layers.37.self_attn.o_proj": {"inputs": [[[46.75]]], "outputs": [[[70.5]], [[2.7563508687213545e+26]]], "params": {"weight": [[0.41015625]]}}, "model.layers.37.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.80859375]], [[97.0]]]}, "model.layers.37.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[53.5]]]}, "model.layers.37.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.80859375]]]}, "model.layers.37.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[45.5]]]}, "model.layers.37.self_attn.attn.impl.k_cache": {"inputs": [[[97.0]]]}, "model.layers.37.self_attn.attn.impl.v_cache": {"inputs": [[[53.5]]]}, "model.layers.37.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[103.0]], [[97.0]], [[53.5]]], "outputs": [[[46.75]], [[1.0]]]}, "model.layers.37.mlp.gate_up_proj": {"inputs": [[[142.0]]], "params": {"weight": [[0.25390625]]}}, "model.layers.37.mlp.down_proj": {"inputs": [[[1400.0]]], "outputs": [[[780.0]], [[1.1992544130577121e+27]]], "params": {"weight": [[0.54296875]]}}, "model.layers.38.self_attn.qkv_proj": {"inputs": [[[167.0]]], "params": {"weight": [[0.2001953125]]}}, "model.layers.38.self_attn.o_proj": {"inputs": [[[45.25]]], "outputs": [[[201.0]], [[1.4446663544394819e+26]]], "params": {"weight": [[0.408203125]]}}, "model.layers.38.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.58984375]], [[84.5]]]}, "model.layers.38.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[70.5]]]}, "model.layers.38.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.58984375]]]}, "model.layers.38.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[57.25]]]}, "model.layers.38.self_attn.attn.impl.k_cache": {"inputs": [[[84.5]]]}, "model.layers.38.self_attn.attn.impl.v_cache": {"inputs": [[[70.5]]]}, "model.layers.38.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[83.5]], [[83.5]], [[70.5]]], "outputs": [[[45.25]], [[1.0]]]}, "model.layers.38.mlp.gate_up_proj": {"inputs": [[[179.0]]], "params": {"weight": [[0.34765625]]}}, "model.layers.38.mlp.down_proj": {"inputs": [[[1192.0]]], "outputs": [[[636.0]], [[2.7563508687213545e+26]]], "params": {"weight": [[0.41796875]]}}, "model.layers.39.self_attn.qkv_proj": {"inputs": [[[270.0]]], "params": {"weight": [[0.1904296875]]}}, "model.layers.39.self_attn.o_proj": {"inputs": [[[63.75]]], "outputs": [[[356.0]], [[1.3186539708940812e+19]]], "params": {"weight": [[0.48046875]]}}, "model.layers.39.self_attn.attn.impl.matmul_qk": {"inputs": [[[0.76171875]], [[101.5]]]}, "model.layers.39.self_attn.attn.impl.matmul_av": {"inputs": [[[1.0]], [[71.0]]]}, "model.layers.39.self_attn.attn.impl.batch2block_matmul": {"inputs": [[[1.0]], [[0.76171875]]]}, "model.layers.39.self_attn.attn.impl.block2batch_matmul": {"inputs": [[[1.0]], [[61.5]]]}, "model.layers.39.self_attn.attn.impl.k_cache": {"inputs": [[[101.5]]]}, "model.layers.39.self_attn.attn.impl.v_cache": {"inputs": [[[71.0]]]}, "model.layers.39.self_attn.attn.impl.fused_scaled_dot_product_attention": {"inputs": [[[122.5]], [[101.5]], [[69.0]]], "outputs": [[[63.75]], [[1.0]]]}, "model.layers.39.mlp.gate_up_proj": {"inputs": [[[474.0]]], "params": {"weight": [[0.55078125]]}}, "model.layers.39.mlp.down_proj": {"inputs": [[[10176.0]]], "outputs": [[[13696.0]], [[1.150897380273127e+27]]], "params": {"weight": [[0.58984375]]}}, "lm_head": {"inputs": [[[1208.0]]], "params": {"weight": [[0.337890625]]}}}}